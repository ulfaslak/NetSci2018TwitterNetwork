{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for tweets with hashtag '#NetSci2018'\n",
      "Loaded 100 tweets from 100 different users:\n",
      "robysinatra\n",
      "LindaDouw\n",
      "srgtmt\n",
      "MangioniG\n",
      "MilleNeige\n",
      "elisa_omodei\n",
      "netsci15\n",
      "a_baronca\n",
      "narnolddd\n",
      "tiagopeixoto\n",
      "luyibov\n",
      "emanudelfava\n",
      "mar7k\n",
      "RenaudLambiotte\n",
      "juniperlov\n",
      "manlius84\n",
      "LHDnets\n",
      "NetSciX\n",
      "HorEyeJen\n",
      "mario_paolucci\n",
      "ralexbentley\n",
      "anduviera\n",
      "bigdatatales\n",
      "_jgyou\n",
      "jabawack\n",
      "Giuseppe_Jurman\n",
      "spornslab\n",
      "Machine_Leaning\n",
      "ParagonSci_Inc\n",
      "Schr0dingersKat\n",
      "CGraciaLazaro\n",
      "JacobBiamonte\n",
      "NetContagions\n",
      "mtizzoni\n",
      "FrancescoBonchi\n",
      "ciro\n",
      "cosnet_bifi\n",
      "figshare\n",
      "leriomaggio\n",
      "marco_java\n",
      "ewancolman\n",
      "martikagv\n",
      "pratha_sah\n",
      "svscarpino\n",
      "AntoViral\n",
      "_AlexArenas\n",
      "mesosbrodleto\n",
      "RachaelMilwid\n",
      "DAPSworkshop\n",
      "net__worker\n",
      "PLOSNTDs\n",
      "urban_stevie\n",
      "jefferywang0429\n",
      "vcolizza\n",
      "Sandro_Meloni\n",
      "LeonieMueck\n",
      "fede7j\n",
      "dan_marinazzo\n",
      "diestra77\n",
      "PLOSONE\n",
      "serg_arregui\n",
      "PiratePeel\n",
      "all_are\n",
      "mszll\n",
      "KoljaKleineberg\n",
      "leoferres\n",
      "nycbat\n",
      "MindScienceFdn\n",
      "Tatmann9\n",
      "oneofyen\n",
      "BallandiesMC\n",
      "tchambers\n",
      "laetitiagvn\n",
      "rupensa\n",
      "PLOS\n",
      "JeroenJGGeurts\n",
      "dubitareaude\n",
      "SamuelJenness\n",
      "kristamenglish\n",
      "netsci2018\n",
      "sdwfrost\n",
      "niamhoconnor73\n",
      "ryanjgallag\n",
      "bansallab\n",
      "IacopoIacopini\n",
      "tinaeliassi\n",
      "baldellino\n",
      "Ghoshal_G\n",
      "SoBigData\n",
      "ayirpelle\n",
      "k_vanderwaal\n",
      "quant_success\n",
      "deaneckles\n",
      "noamross\n",
      "sycramore\n",
      "net_science\n",
      "ISI_Fondazione\n",
      "lucpappalard\n",
      "joergheber\n",
      "SophieMeakin\n",
      "\n",
      "... saving users\n",
      "\n",
      "Getting like-links for each user:\n",
      "robysinatra 8\n",
      "LindaDouw 18\n",
      "srgtmt 4\n",
      "MangioniG 22\n",
      "MilleNeige 8\n",
      "elisa_omodei 18\n",
      "netsci15 0\n",
      "a_baronca 1\n",
      "narnolddd 4\n",
      "tiagopeixoto 20\n",
      "luyibov 10\n",
      "emanudelfava 16\n",
      "mar7k 0\n",
      "RenaudLambiotte 6\n",
      "juniperlov 28\n",
      "manlius84 25\n",
      "LHDnets 11\n",
      "NetSciX 0\n",
      "HorEyeJen 0\n",
      "mario_paolucci 1\n",
      "ralexbentley 0\n",
      "anduviera 5\n",
      "bigdatatales 38\n",
      "_jgyou 18\n",
      "jabawack 7\n",
      "Giuseppe_Jurman 8\n",
      "spornslab 4\n",
      "Machine_Leaning 6\n",
      "ParagonSci_Inc 3\n",
      "Schr0dingersKat 0\n",
      "CGraciaLazaro 13\n",
      "JacobBiamonte 11\n",
      "NetContagions 10\n",
      "mtizzoni 24\n",
      "FrancescoBonchi 7\n",
      "ciro 26\n",
      "cosnet_bifi 23\n",
      "figshare 0\n",
      "leriomaggio 7\n",
      "marco_java 16\n",
      "ewancolman 9\n",
      "martikagv 8\n",
      "pratha_sah 11\n",
      "svscarpino 27\n",
      "AntoViral 0\n",
      "_AlexArenas 9\n",
      "mesosbrodleto 4\n",
      "RachaelMilwid 1\n",
      "DAPSworkshop 14\n",
      "net__worker 0\n",
      "PLOSNTDs 7\n",
      "urban_stevie 3\n",
      "jefferywang0429 1\n",
      "vcolizza 31\n",
      "Sandro_Meloni 17\n",
      "LeonieMueck 9\n",
      "fede7j 18\n",
      "dan_marinazzo 6\n",
      "diestra77 9\n",
      "PLOSONE 5\n",
      "serg_arregui 11\n",
      "PiratePeel 19\n",
      "all_are 11\n",
      "mszll 7\n",
      "KoljaKleineberg 4\n",
      "leoferres 9\n",
      "nycbat 3\n",
      "MindScienceFdn 0\n",
      "Tatmann9 10\n",
      "oneofyen 19\n",
      "BallandiesMC 5\n",
      "tchambers 0\n",
      "laetitiagvn 3\n",
      "rupensa 5\n",
      "PLOS 6\n",
      "Warning: Rate limit exceeded (user: JeroenJGGeurts), waiting 15 minutes\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_user_links' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-16b8868bdb3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Warning: Rate limit exceeded (user: %s), waiting 15 minutes\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mlinks_user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_user_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_user_links' is not defined"
     ]
    }
   ],
   "source": [
    "from twitter import Twitter, OAuth, TwitterHTTPError, TwitterStream\n",
    "import twitter\n",
    "import os\n",
    "import urllib\n",
    "import json\n",
    "import datetime as dt\n",
    "from dateutil import parser\n",
    "from time import sleep\n",
    "import re\n",
    "\n",
    "# twitter tokens, keys, secrets, and Twitter handle in the following variables\n",
    "CONSUMER_KEY = 'E19oBd9qdE1wXWiyixMfrubbI'\n",
    "CONSUMER_SECRET ='IU5qiEwHJgKAVJN0fXMux79yIzsMISSjLORB3j8sXXvUFddlnV'\n",
    "OAUTH_TOKEN = '2749655899-u4geaWEZHlCXtvk12wlVJ84JmSX4HIQuD3FEsDQ'\n",
    "OAUTH_TOKEN_SECRET = 'NlUL020uY5mXW4nFonFI2PgWDMguv6V2aF9QGGQkCAly8'\n",
    "TWITTER_HANDLE = \"ulfaslak\"\n",
    "TWITTER_ID = 2749655899\n",
    "\n",
    "def search_tweets(q, count=100, result_type=\"recent\", lang='en'):\n",
    "    return t.search.tweets(q=q, result_type=result_type, count=count, lang=lang)\n",
    "\n",
    "def get_user_links_likes(user):\n",
    "    return [\n",
    "        (user, tweet['user']['screen_name'], str(parser.parse(tweet['created_at'])))\n",
    "        for tweet in t.favorites.list(screen_name=user, count=100)\n",
    "        if tweet['user']['screen_name'] in users\n",
    "    ]\n",
    "\n",
    "def update_users(new_users):\n",
    "    with open('users', 'r') as fp:\n",
    "        users = json.load(fp)\n",
    "    with open('users', 'w') as fp:\n",
    "        users = sorted(set(users) | set(new_users))\n",
    "        json.dump(users, fp)\n",
    "    return users\n",
    "    \n",
    "def update_links(new_links, filename):\n",
    "    with open(filename, 'r') as fp:\n",
    "        links = [tuple(l.split(\",\")) for l in fp.read().split(\"\\n\")[1:]]\n",
    "    with open(filename, 'w') as fp:\n",
    "        links = sorted(set(links) | set(new_links))\n",
    "        fp.write(\"source,target,datetime\\n\")\n",
    "        fp.write(\"\\n\".join([\",\".join(l) for l in links]))\n",
    "        \n",
    "t = Twitter(auth=OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET, CONSUMER_KEY, CONSUMER_SECRET))\n",
    "\n",
    "# Get users that tweeted with #netsci2018 hashtag\n",
    "print \"Searching for tweets with hashtag '#NetSci2018'\"\n",
    "collection_tweets = search_tweets(\"#netsci2018\")['statuses']\n",
    "print \"Loaded %d tweets\"  % len(collection_tweets),\n",
    "\n",
    "print \"from\",\n",
    "users = sorted(set(update_users([tweet['user']['screen_name'] for tweet in collection_tweets])))  # Everybody who has tweeted\n",
    "#users = users | set([\n",
    "#    tagged_user\n",
    "#    for tweet in collection_tweets\n",
    "#    for tagged_user in re.findall(r\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9_]+)\", tweet['text'])\n",
    "#])\n",
    "print \"%d different users:\" %len(users)\n",
    "\n",
    "print \"\\n\".join(users)\n",
    "print \"\\n... saving users\"\n",
    "\n",
    "# For each, produce links from their favorites\n",
    "print \"\\nGetting like-links for each user:\"\n",
    "links_likes = []\n",
    "for user in users:\n",
    "    try:\n",
    "        links_user = get_user_links_likes(user)\n",
    "    except twitter.TwitterHTTPError:\n",
    "        print \"Warning: Rate limit exceeded (user: %s), waiting 15 minutes\" % user\n",
    "        sleep(60 * 15)\n",
    "        links_user = get_user_links_likes(user)\n",
    "        continue\n",
    "        \n",
    "    print user, len(links_user)\n",
    "    links_likes.extend(links_user)\n",
    "\n",
    "print \"\\nTotal:\", len(links)\n",
    "\n",
    "# Produce retweet links\n",
    "links_retweets = []\n",
    "for tweet in collection_tweets:\n",
    "    if 'retweeted_status' in tweet and tweet['retweeted_status']['user']['screen_name'] in users:\n",
    "        links_retweets.append(\n",
    "            (tweet['user']['screen_name'], tweet['retweeted_status']['user']['screen_name'], str(parser.parse(tweet['created_at'])))\n",
    "        )\n",
    "        \n",
    "# Produce tag links\n",
    "links_tags = []\n",
    "for tweet in collection_tweets:\n",
    "    if 'retweeted_status' not in tweet:\n",
    "        for tagged_user in re.findall(r\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9_]+)\", tweet['text']):\n",
    "            if tagged_user:\n",
    "                links_tags.append(\n",
    "                    (tweet['user']['screen_name'], tagged_user, str(parser.parse(tweet['created_at'])))\n",
    "                )\n",
    "                    \n",
    "\n",
    "\n",
    "print \"\\n... saving links\"\n",
    "update_links(links_likes, \"links_likes.csv\")\n",
    "update_links(links_retweets, \"links_retweets.csv\")\n",
    "update_links(links_tags, \"links_tags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JeroenJGGeurts 1\n",
      "dubitareaude 0\n",
      "SamuelJenness 4\n",
      "kristamenglish 1\n",
      "netsci2018 33\n",
      "sdwfrost 3\n",
      "niamhoconnor73 1\n",
      "ryanjgallag 14\n",
      "bansallab 11\n",
      "IacopoIacopini 8\n",
      "tinaeliassi 14\n",
      "baldellino 3\n",
      "Ghoshal_G 5\n",
      "SoBigData 2\n",
      "ayirpelle 0\n",
      "k_vanderwaal 0\n",
      "quant_success 5\n",
      "deaneckles 2\n",
      "noamross 2\n",
      "sycramore 0\n",
      "net_science 17\n",
      "ISI_Fondazione 10\n",
      "lucpappalard 6\n",
      "joergheber 9\n",
      "SophieMeakin 4\n",
      "\n",
      "Total: 27\n",
      "\n",
      "... saving links\n"
     ]
    }
   ],
   "source": [
    "for i, user in enumerate(users):\n",
    "    if i < 75: continue\n",
    "    try:\n",
    "        links_user = get_user_links_likes(user)\n",
    "    except twitter.TwitterHTTPError:\n",
    "        print \"Warning: Rate limit exceeded (user: %s), waiting 15 minutes\" % user\n",
    "        sleep(60 * 15)\n",
    "        links_user = get_user_links_likes(user)\n",
    "        continue\n",
    "        \n",
    "    print user, len(links_user)\n",
    "    links_likes.extend(links_user)\n",
    "\n",
    "print \"\\nTotal:\", len(links)\n",
    "\n",
    "# Produce retweet links\n",
    "links_retweets = []\n",
    "for tweet in collection_tweets:\n",
    "    if 'retweeted_status' in tweet and tweet['retweeted_status']['user']['screen_name'] in users:\n",
    "        links_retweets.append(\n",
    "            (tweet['user']['screen_name'], tweet['retweeted_status']['user']['screen_name'], str(parser.parse(tweet['created_at'])))\n",
    "        )\n",
    "        \n",
    "# Produce tag links\n",
    "links_tags = []\n",
    "for tweet in collection_tweets:\n",
    "    if 'retweeted_status' not in tweet:\n",
    "        for tagged_user in re.findall(r\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9_]+)\", tweet['text']):\n",
    "            if tagged_user:\n",
    "                links_tags.append(\n",
    "                    (tweet['user']['screen_name'], tagged_user, str(parser.parse(tweet['created_at'])))\n",
    "                )\n",
    "                    \n",
    "\n",
    "\n",
    "print \"\\n... saving links\"\n",
    "update_links(links_likes, \"links_likes.csv\")\n",
    "update_links(links_retweets, \"links_retweets.csv\")\n",
    "update_links(links_tags, \"links_tags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "update_links(links_retweets, \"links_retweets.csv\")\n",
    "update_links(links_tags, \"links_tags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'AntoViral',\n",
       " u'BallandiesMC',\n",
       " u'CGraciaLazaro',\n",
       " u'DAPSworkshop',\n",
       " u'FrancescoBonchi',\n",
       " u'Ghoshal_G',\n",
       " u'Giuseppe_Jurman',\n",
       " u'HorEyeJen',\n",
       " u'ISI_Fondazione',\n",
       " u'IacopoIacopini',\n",
       " u'JacobBiamonte',\n",
       " u'JeroenJGGeurts',\n",
       " u'KoljaKleineberg',\n",
       " u'LHDnets',\n",
       " u'LeonieMueck',\n",
       " u'LindaDouw',\n",
       " u'Machine_Leaning',\n",
       " u'MangioniG',\n",
       " u'MilleNeige',\n",
       " u'MindScienceFdn',\n",
       " u'NetContagions',\n",
       " u'NetSciX',\n",
       " u'PLOS',\n",
       " u'PLOSNTDs',\n",
       " u'PLOSONE',\n",
       " u'ParagonSci_Inc',\n",
       " u'PiratePeel',\n",
       " u'RachaelMilwid',\n",
       " u'RenaudLambiotte',\n",
       " u'SamuelJenness',\n",
       " u'Sandro_Meloni',\n",
       " u'Schr0dingersKat',\n",
       " u'SoBigData',\n",
       " u'SophieMeakin',\n",
       " u'Tatmann9',\n",
       " u'_AlexArenas',\n",
       " u'_jgyou',\n",
       " u'a_baronca',\n",
       " u'all_are',\n",
       " u'anduviera',\n",
       " u'ayirpelle',\n",
       " u'baldellino',\n",
       " u'bansallab',\n",
       " u'bigdatatales',\n",
       " u'ciro',\n",
       " u'cosnet_bifi',\n",
       " u'dan_marinazzo',\n",
       " u'deaneckles',\n",
       " u'diestra77',\n",
       " u'dubitareaude',\n",
       " u'elisa_omodei',\n",
       " u'emanudelfava',\n",
       " u'ewancolman',\n",
       " u'fede7j',\n",
       " u'figshare',\n",
       " u'jabawack',\n",
       " u'jefferywang0429',\n",
       " u'joergheber',\n",
       " u'juniperlov',\n",
       " u'k_vanderwaal',\n",
       " u'kristamenglish',\n",
       " u'laetitiagvn',\n",
       " u'leoferres',\n",
       " u'leriomaggio',\n",
       " u'lucpappalard',\n",
       " u'luyibov',\n",
       " u'manlius84',\n",
       " u'mar7k',\n",
       " u'marco_java',\n",
       " u'mario_paolucci',\n",
       " u'martikagv',\n",
       " u'mesosbrodleto',\n",
       " u'mszll',\n",
       " u'mtizzoni',\n",
       " u'narnolddd',\n",
       " u'net__worker',\n",
       " u'net_science',\n",
       " u'netsci15',\n",
       " u'netsci2018',\n",
       " u'niamhoconnor73',\n",
       " u'noamross',\n",
       " u'nycbat',\n",
       " u'oneofyen',\n",
       " u'pratha_sah',\n",
       " u'quant_success',\n",
       " u'ralexbentley',\n",
       " u'robysinatra',\n",
       " u'rupensa',\n",
       " u'ryanjgallag',\n",
       " u'sdwfrost',\n",
       " u'serg_arregui',\n",
       " u'spornslab',\n",
       " u'srgtmt',\n",
       " u'svscarpino',\n",
       " u'sycramore',\n",
       " u'tchambers',\n",
       " u'tiagopeixoto',\n",
       " u'tinaeliassi',\n",
       " u'urban_stevie',\n",
       " u'vcolizza'}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'cosnet_bifi'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet['retweeted_status']['user']['screen_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'cosnet_bifi',\n",
       " u'serg_arregui',\n",
       " u'Sanz_Jq',\n",
       " u'IacopoIacopini',\n",
       " u'netplexity',\n",
       " u'cosnet_bifi',\n",
       " u'serg_arregui',\n",
       " u'Sanz_Jq',\n",
       " u'emanudelfava',\n",
       " u'jabawack',\n",
       " u'oneofyen',\n",
       " u'aaronclauset',\n",
       " u'leman_akogl',\n",
       " u'emanudelfava',\n",
       " u'jabawack',\n",
       " u'ciro',\n",
       " u'jabawack',\n",
       " u'TAlexPerkins',\n",
       " u'casey_zipfel',\n",
       " u'mtizzoni',\n",
       " u'EcoHealthNYC',\n",
       " u'cosnet_bifi',\n",
       " u'netsci2018',\n",
       " u'PiratePeel',\n",
       " u'serg_arregui',\n",
       " u'Sanz_Jq',\n",
       " u'lucpappalard',\n",
       " u'fede7j',\n",
       " u'netsci2018',\n",
       " u'lucpappalard',\n",
       " u'fede7j',\n",
       " u'netsci2018',\n",
       " u'rionbr',\n",
       " u'LuisMateusRocha',\n",
       " u'CNS',\n",
       " u'sdwfrost',\n",
       " u'chpoletto',\n",
       " u'netsci2018',\n",
       " u'mtizzoni',\n",
       " u'cosnet_bifi',\n",
       " u'eugeValdano',\n",
       " u'shaipilo',\n",
       " u'Giuseppe_Jurman',\n",
       " u'PLOSONE',\n",
       " u'NetSci2018',\n",
       " u'LeonieMueck',\n",
       " u'PLOSONE',\n",
       " u'NetSci2018',\n",
       " u'LeonieMueck',\n",
       " u'sdwfrost',\n",
       " u'm_rosvall',\n",
       " u'tiagopeixoto',\n",
       " u'shaipilo',\n",
       " u'Giuseppe_Jurman',\n",
       " u'mtizzoni',\n",
       " u'LHDnets',\n",
       " u'PiratePeel',\n",
       " u'victorveitch',\n",
       " u'aaronclauset',\n",
       " u'Giuseppe_Jurman',\n",
       " u'a_baronca',\n",
       " u'a_baronca',\n",
       " u'PLOSONE',\n",
       " u'NetSci2018',\n",
       " u'LeonieMueck',\n",
       " u'NatureComms',\n",
       " u'lucpappalard',\n",
       " u'aaronclauset',\n",
       " u'netsci2018',\n",
       " u'lucpappalard',\n",
       " u'fede7j',\n",
       " u'netsci2018',\n",
       " u'lucpappalard',\n",
       " u'netsci2018',\n",
       " u'quant_success',\n",
       " u'netsci2018',\n",
       " u'quant_success',\n",
       " u'netplexity',\n",
       " u'netsci2018',\n",
       " u'lucpappalard',\n",
       " u'msantolini',\n",
       " u'netsci2018',\n",
       " u'lucpappalard',\n",
       " u'netsci2018',\n",
       " u'lucpappalard',\n",
       " u'netsci2018',\n",
       " u'quant_success',\n",
       " u'FerraginaTeach',\n",
       " u'netsci2018',\n",
       " u'lucpappalard',\n",
       " u'FerraginaTeach',\n",
       " u'netsci2018',\n",
       " u'tinaeliassi',\n",
       " u'ingo_S',\n",
       " u'tinaeliassi',\n",
       " u'ingo_S',\n",
       " u'ingo_S',\n",
       " u'MilleNeige',\n",
       " u'PiratePeel',\n",
       " u'victorveitch',\n",
       " u'JacobBiamonte',\n",
       " u'netsci2018',\n",
       " u'lucpappalard',\n",
       " u'netsci2018',\n",
       " u'robysinatra',\n",
       " u'a_baronca',\n",
       " u'quant_success',\n",
       " u'netplexity',\n",
       " u'netsci2018',\n",
       " u'emanudelfava',\n",
       " u'jabawack',\n",
       " u'mtizzoni',\n",
       " u'LHDnets',\n",
       " u'PiratePeel',\n",
       " u'victorveitch',\n",
       " u'PLOSONE',\n",
       " u'NetSci2018',\n",
       " u'victorveitch',\n",
       " u'KoljaKleineberg',\n",
       " u'NatureComms',\n",
       " u'mtizzoni',\n",
       " u'EcoHealthNYC',\n",
       " u'svscarpino',\n",
       " u'joel_c_miller',\n",
       " u'lucpappalard',\n",
       " u'aaronclauset',\n",
       " u'netsci2018',\n",
       " u'KoljaKleineberg',\n",
       " u'NatureComms',\n",
       " u'a_baronca',\n",
       " u'aaronclauset',\n",
       " u'netsci2018',\n",
       " u'juniperlov',\n",
       " u'LHDnets',\n",
       " u'IacopoIacopini',\n",
       " u'netplexity',\n",
       " u'vcolizza',\n",
       " u'jelenagrr',\n",
       " u'PiratePeel',\n",
       " u'pholme',\n",
       " u'NetContagions',\n",
       " u'PiratePeel',\n",
       " u'Tatmann9',\n",
       " u'lucpappalard',\n",
       " u'iPif',\n",
       " u'netsci2018',\n",
       " u'lucpappalard',\n",
       " u'iPif',\n",
       " u'netsci2018',\n",
       " u'lucpappalard',\n",
       " u'iPif',\n",
       " u'netsci2018',\n",
       " u'lucpappalard',\n",
       " u'iPif',\n",
       " u'netsci2018',\n",
       " u'iPif',\n",
       " u'netsci2018',\n",
       " u'svscarpino',\n",
       " u'sociopatte',\n",
       " u'NetContagions',\n",
       " u'juniperlov',\n",
       " u'LHDnets',\n",
       " u'IacopoIacopini',\n",
       " u'netplexity',\n",
       " u'ISI_Fondazione',\n",
       " u'ISI_Fondazione',\n",
       " u'juniperlov',\n",
       " u'LHDnets',\n",
       " u'elisa_omodei',\n",
       " u'ccs18gr',\n",
       " u'lucpappalard',\n",
       " u'fede7j',\n",
       " u'netsci2018',\n",
       " u'lucpappalard',\n",
       " u'aaronclauset',\n",
       " u'netsci2018',\n",
       " u'fede7j',\n",
       " u'netsci2018',\n",
       " u'PiratePeel',\n",
       " u'Tatmann9',\n",
       " u'KoljaKleineberg',\n",
       " u'NatureComms',\n",
       " u'ISI_Fondazione',\n",
       " u'mtizzoni',\n",
       " u'LHDnets',\n",
       " u'quant_success',\n",
       " u'netsci2018',\n",
       " u'dan_marinazzo',\n",
       " u'jgonicor',\n",
       " u'netsci2018',\n",
       " u'PiratePeel',\n",
       " u'tiagopeixoto',\n",
       " u'dan_marinazzo',\n",
       " u'jgonicor']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for tweet in collection_tweets for name in re.findall(r\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9_]+)\", tweet['text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
